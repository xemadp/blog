<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>  So you think you can tell Heaven from Hell </title>
<style>
    body{
        margin:1em auto;
        max-width:40em;
        padding:0 .62em;
        font: sans-serif
    }
    blockquote, pre, code {
        background-color: #f0f0f0;
        border-color: #222;
    }
    h1,h2,h3 {
        line-height:1.2;
    }
    @media print{
        body{
            max-width:none
        }
    }
    @media (prefers-color-scheme: dark){
        body {color:#fff;background:#111}
        a:link {color:#cdf}
        a:hover, a:visited:hover {color:#def}
        a:visited {color:#dcf}
        blockquote, pre, code {
                background-color: #2f2f2f;
        }
    }
</style>

<body>
    <div>
        
<!---Generated by esbu--->


<!---the creation date is: 2025-02-16 18:23:39 --->


<h1>So you think you can tell Heaven from Hell</h1>

<hr>


<p> Let&rsquo;s create a parser for noam, for now we will use tools that create parsers for us, maybe later we&rsquo;ll focus on implementing one from scratch, however
 our aim for now is to understand how compilers work, and creating one that works. We&rsquo;ll modify our lexer which is basically a lisp thunk that is modified from <a href="https://xemadp.github.io/blog/entries/compilerIII.html">before</a> to return TOKEN and value of a lexeme when used by the parser that we&rsquo;re going to make.</p>

<p><p align="center" style="line-height:1.5">
<img src="../pics/reddragon.png" alt="Complexity Of Compiler Design Doesn't stand a chance!"  style="width:100%;height:auto;max-width:500px" />
</p></p>

<p>In the lexical analysis phase, we used the power of DFAs ( Regular Expressions or Regular Grammars) to check if our input file,
is indeed made up of words that are recognized in our language as valid. Take English for example, if we are given the input stream
<code>Here Is An English Sente&amp;#%nc@e</code>, we are able to recognize that <code>Here</code>, <code>Is</code>, <code>An</code> and <code>English</code> are all
valid English words, but <code>Sente&amp;#%nc@e</code> is not. Regular Expressions let us do this, but they fall short when it comes to
finding out whether a given sentence is <em>grammatically</em> correct or not,
let&rsquo;s say we have <code>Another in English Sentence Here is</code> as input,
RegExp will tell us that this sentence is made up of valid English words
But it can&rsquo;t really tell if it has valid English grammatical structure.
This is also called Syntactical Analysis.</p>

<p>Here is where the need to use context free grammars becomes apparent.
The same principle is present in Compiler Design. We want to make sure
the input program is syntactically correct.</p>

<p>We will use cl-yacc to create the parser and print out how the input program is derived from the grammar.</p>

<hr>


<h1>Language Specification and Context Free Grammars</h1>

<p>Language Specification is basically an instruction set that shows us how different sentential forms can be derived in our language.
A sentential form is basically a configuration of some sentence in our language before or after it is derived.
for example if our grammar is like this :</p>

<p><pre><code>expression -&gt; expression + expression
expression -&gt; 2
</code></pre>
then <code>expression + 2</code>, <code>2+2</code>, <code>expression + expression</code>, <code>2 + expression</code> would all be sentential forms.
a sentential form that can derive nothing, is called a sentence.</p>

<p><code>2+2</code> is a sentence in this example.</p>

<p>The Specification of most programming languages are in backaus-naur-form(BNF) which is just another way of representing Context Free Grammars.
here how the noam specification looks like in extended bnf ( ebnf ) for now:</p>

<p><pre><code>program = { automaton_declaration | verification_declaration };

automaton_declaration = "Automaton" identifier "{"
state_declaration
start_state
accept_states
alphabet_declaration 
transition_declaration

"}";

state_declaration = "states" "{" {state, ","} state "}", ";";
start_state = "start" state, ";";
accept_states = "accept" "{" { state, "," } state "}", ";";
state = identifier;

alphabet_declaration = "inputset" "{" {string, ","}, string "}", ";";

transition_declaration = dfa_transition;
dfa_transition = "transition" state, ":" { transition_rule }

transition_rule = "on" string,"," "goto" state, ";";

verification_declaration = "Verify" identifier "{"
property_list
"}";

property_list = { property, ";"};
property = reachable | acceptance | determinism | emptiness | equivalence;
reachable = "canreach" "{" { state, "," } state  "}";
acceptance = "accepts"  "{" { string,"," } string "}";
determinism = "deterministic";
emptiness = "isempty";
equivalence = "equal" "{" { identifier,"," } identifier "}" ;
termination = "terminates" "{" { string, "," } string "}";

identifier = letter , { letter | digit | "_" } ;

letter =  "A" | "B" | "C" | "D" | "E" | "F" | "G"
       | "H" | "I" | "J" | "K" | "L" | "M" | "N"
       | "O" | "P" | "Q" | "R" | "S" | "T" | "U"
       | "V" | "W" | "X" | "Y" | "Z" | "a" | "b"
       | "c" | "d" | "e" | "f" | "g" | "h" | "i"
       | "j" | "k" | "l" | "m" | "n" | "o" | "p"
       | "q" | "r" | "s" | "t" | "u" | "v" | "w"
       | "x" | "y" | "z";

digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;

symbol = "[" | "]" | "{" | "}" | "(" | ")" | "&lt;" | "&gt;"
       | "'" | '"' | "=" | "|" | "." | "," | ";" | "-" 
       | "+" | "*" | "?" | "\n" | "\t" | "\r" | "\f" | "\b" ;

string = { character };
character = letter | digit | symbol | "_" | " " ;
</code></pre>
</p>

<h2>Context Free Grammars</h2>

<p>Let&rsquo;s formally define CFGs.
Let&rsquo;s say <em>G</em> is a context free language. Then G is a 4-tuple (V,T,P,S)
where</p>

<ul>
<li><em>V</em> is a finite set called the <em>variables</em> or <em>Nonterminals</em>,</li>
<li><em>T</em> is a finite set, disjoin from <em>V</em>, called the <em>terminals</em>,</li>
<li><em>P</em> is a finite set of <em>production rules</em>, with each rule being a variable and a string of variables and terminals, and</li>
<li><em>S</em> is the start variable.</li>
</ul>


<p>We start with the start variable S,
Each time a <em>nonterminal</em> is chosen and the production rule that has this nonterminal as it&rsquo;s left
hand ( head ) is used to derive other sentential forms.</p>

<p>Terminals can never be the head of some production meaning they cannot derive anything.
A sentence is composed of only terminals.</p>

<p>The Start Variable of the noam specification would be the <code>program</code> variable and the
production of which <code>program</code> is the head, would be <code>program -&gt; automaton_declaration | verification_declaration</code>
we want to some how analyze our input file and find out which of these production rules are used to derive that sentence.</p>

<p>Utilizing the power of Context Free Grammars, we can find a lot about the structure of a given input stream, given the grammar
specification.</p>

<hr>


<h1>What is a Parser</h1>

<p><p align="center" style="line-height:1.5">
<img src="../pics/lex2parse.png" alt=""  style="width:100%;height:auto;max-width:350px" />
</p></p>

<p>A parser is a program, that takes tokens from lexer, and tries to make sense of them syntactically
while looking at a pre-defined grammar ( tries to create syntax trees ).
A parser is effectively a really big state machine that decides
what part of the input ( sentential form ), corresponds to what part
of the grammar productions.
There are different type of parsers, Top-Down parsers, Bottom-up Parsers and more.
For the sake of this blog post, we&rsquo;ll talk about bottom-up parsing since
that is the method mostly used to create parsers for programming languages.
Most parser generators also use bottom-up parsing techniques to create parsers.</p>

<p><p align="center" style="line-height:1.5">
<img src="../pics/parserwiz.png" alt="Syntactical Analysis"  style="width:100%;height:auto;max-width:370px" />
<br>
<br>
Wizard as Parser, Creating A parse tree for <code>Ex Arboribus Cognitio</code>
<br>
From Trees, Knowledge
</p></p>

<h2>Bottom Up Parsing</h2>

<p>A bottom-up parser, tries to start from the sentence given as input and
build it&rsquo;s way up to the start variable, by doing two things :</p>

<p>It Either:</p>

<ul>
<li>Shifts ( Consumes ) input into a stack or,</li>
<li>Reduces ( replaces some of the top contents of the stack ) with a production head, defined in the grammar.</li>
</ul>


<p>It is basically a really big state machine that decides whether to shift/reduce when given a token.</p>

<p>The class of Context Free Languages that can be parsed by bottom-up parsers are called LR(k) languages.
It stands for Left-to-Right Rightmost derivation in reverse, and k is the number of character lookaheads that is allowed.</p>

<p>In some cases some conflicts can happen ( when the parser doesn&rsquo;t know if it should shift or reduce )
We can get by easily by looking at a special type of languages that parsed with LALR(1) parsers.</p>

<p>For the most part, conflicts can be avoided in the parsing table designed for these languages.</p>

<p>That may be the reason why most parser generators like yacc/bison create LALR(1) parsers.</p>

<hr> 


<h1>Creating a parser for noam</h1>

<p>In this post, we&rsquo;ll create a parser for noam that effectively parses the noam input file and prints the reductions performed by the parser in order of them taking effect.</p>

<p>Let&rsquo;s first Modify the lexer we had from earlier to return a VALUE and lexeme when finding a token.</p>

<p>lexer.lisp:</p>

<p><pre><code>(ql:quickload '(:cl-lex))

(defpackage :noam-lexer
  (:use :cl :cl-lex)
  (:export 
    #:noam-lexer
   :AUTOMATON_KW :STATES_KW :START_KW :ACCEPT_KW :VERIFY_KW 
   :INPUTSET_KW :TRANSITION_KW :ON_KW :GOTO_KW :CANREACH_KW 
   :ACCEPTS_KW :DETERMINISTIC_KW :ISEMPTY_KW :EQUAL_KW :TERMINATES_KW 
   :SEMICOLON :LBRACE :RBRACE :COMMA :COLON 
   :IDENTIFIER :STRING))
    

(in-package :noam-lexer)

;;Noam-lexer
(define-string-lexer noam-lexer
  
  ;; Ignore \t and newlines.
  ("[\\t\\n]+" nil)  
  
  
  ;; Reserved keywords.
  ("accepts"           (return (values 'ACCEPTS_KW $@)))
  ("Automaton"         (return (values 'AUTOMATON_KW $@)))
  ("states"            (return (values 'STATES_KW $@)))
  ("start"             (return (values 'START_KW $@)))
  ("accept"            (return (values 'ACCEPT_KW $@)))
  ("Verify"            (return (values 'VERIFY_KW $@)))
  ("inputset"          (return (values 'INPUTSET_KW $@)))
  ("transition"        (return (values 'TRANSITION_KW $@)))
  ("on"                (return (values 'ON_KW $@)))
  ("goto"              (return (values 'GOTO_KW $@)))
  ("canreach"          (return (values 'CANREACH_KW $@)))
  ("deterministic"     (return (values 'DETERMINISTIC_KW $@)))
  ("isempty"           (return (values 'ISEMPTY_KW $@)))
  ("terminates"        (return (values 'TERMINATES_KW $@)))
  ("equal"             (return (values 'EQUAL_KW $@)))

  (";"                 (return (values 'SEMICOLON $@)))
  (","                 (return (values 'COMMA $@)))
  ("{"                 (return (values 'LBRACE $@)))
  ("}"                 (return (values 'RBRACE $@)))
  (":"                 (return (values 'COLON $@)))


  ;; STRING
  ("\\\"[a-zA-Z0-9_ ]*\\\"" 
   (return (values 'STRING $@)))

  ;; IDENTIFIER
  ("[a-zA-Z][a-zA-Z0-9_]*" 
   (return (values 'IDENTIFIER $@)))

  )
</code></pre>
After looking at some <a href="https://www.irif.fr/~jch/software/cl-yacc/cl-yacc.html">cl-yacc manual</a>
We find that in order to create a parser using cl-yacc
we must use the <code>define-parser</code> macro. This macro generates a parser and binds it to the special variable <em>name</em>.
First we need to specify the start-symbol and terminals:
<pre><code>(define-parser *noam-print-reductions*
  (:start-symbol program)
  (:terminals (AUTOMATON_KW STATES_KW START_KW ACCEPT_KW VERIFY_KW
               INPUTSET_KW TRANSITION_KW ON_KW GOTO_KW 
               CANREACH_KW ACCEPTS_KW DETERMINISTIC_KW ISEMPTY_KW EQUAL_KW TERMINATES_KW 
               SEMICOLON LBRACE RBRACE COMMA COLON
               IDENTIFIER STRING)) 
</code></pre>
Then we can go ahead and put our grammar rules here is the grammar rule for the production <code>state_declaration -&gt; states { ID_LIST };</code> in cl-yacc:</p>

<p><pre><code>(state-declaration
 (STATES_KW LBRACE identifier-list RBRACE SEMICOLON 
  (lambda (states-kw lbrace ids rbrace semicolon)
    (format t "state_declaration -&gt; STATES_KW LBRACE identifier_list RBRACE SEMICOLON~%"))))
</code></pre>
The rest is basically doing the same for all of our production rules.
Here is the complete parser implementation :</p>

<p><pre><code>(define-parser *noam-print-reductions*
  (:start-symbol program)
  (:terminals (AUTOMATON_KW STATES_KW START_KW ACCEPT_KW VERIFY_KW
               INPUTSET_KW TRANSITION_KW ON_KW GOTO_KW 
               CANREACH_KW ACCEPTS_KW DETERMINISTIC_KW ISEMPTY_KW EQUAL_KW TERMINATES_KW 
               SEMICOLON LBRACE RBRACE COMMA COLON
               IDENTIFIER STRING)) 

(program
  (declist (lambda (token)
               (format t "program -&gt; declist~%")
               )))

(dec
 (automaton-declaration (lambda (token)
             (format t "dec -&gt; automaton_declaration~%")
             ))
 (verification-declaration (lambda (token)
             (format t "dec -&gt; verification_declaration~%")
             )))

(declist
  (dec declist (lambda (tx ty)
             (format t "declist -&gt; dec declist~%")
             ))

  ((lambda ()
             (format t "declist -&gt; epsilon~%")
             ))
)

(automaton-declaration
 (AUTOMATON_KW IDENTIFIER LBRACE 
  state-declaration 
  start-state 
  accept-states 
  alphabet-declaration 
  transition-declaration-list 
  RBRACE 
  (lambda (automaton-kw id lbrace state-dec start accept alphabet trans rbrace)
    (format t "automaton_declaration -&gt; AUTOMATON_KW IDENTIFIER LBRACE state_declaration start_state accept_states alphabet_declaration transition_declaration_list RBRACE~%"))))

(state-declaration
 (STATES_KW LBRACE identifier-list RBRACE SEMICOLON 
  (lambda (states-kw lbrace ids rbrace semicolon)
    (format t "state_declaration -&gt; STATES_KW LBRACE identifier_list RBRACE SEMICOLON~%"))))

(start-state
 (START_KW IDENTIFIER SEMICOLON
  (lambda (start-kw id semicolon)
    (format t "start_state -&gt; START_KW IDENTIFIER SEMICOLON~%"))))

(accept-states
 (ACCEPT_KW LBRACE identifier-list RBRACE SEMICOLON
  (lambda (accept-kw lbrace ids rbrace semicolon)
    (format t "accept_states -&gt; ACCEPT_KW LBRACE identifier_list RBRACE SEMICOLON~%"))))

(alphabet-declaration
 (INPUTSET_KW LBRACE string-list RBRACE SEMICOLON
  (lambda (inputset-kw lbrace strings rbrace semicolon)
    (format t "alphabet_declaration -&gt; INPUTSET_KW LBRACE string_list RBRACE SEMICOLON~%"))))

(transition-declaration-list
 (transition-declaration transition-declaration-list 
  (lambda (trans-dec trans-list)
    (format t "transition_declaration_list -&gt; transition_declaration transition_declaration_list~%")))

 (transition-declaration 
  (lambda (trans-dec)
    (format t "transition_declaration_list -&gt; transition_declaration~%"))))

(transition-declaration
 (dfa-transition 
  (lambda (dfa-trans)
    (format t "transition_declaration -&gt; dfa_transition~%"))))

(dfa-transition
 (TRANSITION_KW IDENTIFIER COLON transition-rule-list
  (lambda (trans-kw id colon rules)
    (format t "dfa_transition -&gt; TRANSITION_KW IDENTIFIER COLON transition_rule_list~%"))))

(transition-rule
 (ON_KW STRING COMMA GOTO_KW IDENTIFIER SEMICOLON
  (lambda (on-kw str comma goto-kw id semicolon)
    (format t "transition_rule -&gt; ON_KW STRING COMMA GOTO_KW IDENTIFIER SEMICOLON~%"))))

(verification-declaration
 (VERIFY_KW IDENTIFIER LBRACE property-list RBRACE
  (lambda (verify-kw id lbrace props rbrace)
    (format t "verification_declaration -&gt; VERIFY_KW IDENTIFIER LBRACE property_list RBRACE~%"))))

(property-list
 (property SEMICOLON property-list
  (lambda (prop semicolon prop-list)
    (format t "property_list -&gt; property SEMICOLON property_list~%")))
  (property SEMICOLON  ; 
  (lambda (prop semicolon)
    (format t "property_list -&gt; property SEMICOLON~%")))

  (() ; 
  (lambda ()
    (format t "property_list -&gt; epsilon~%"))))


(property
 (reachable 
  (lambda (reach)
    (format t "property -&gt; reachable~%")))
 (acceptance 
  (lambda (accept)
    (format t "property -&gt; acceptance~%")))
 (determinism 
  (lambda (det)
    (format t "property -&gt; determinism~%")))
 (emptiness 
  (lambda (empty)
    (format t "property -&gt; emptiness~%")))
 (equivalence 
  (lambda (equiv)
    (format t "property -&gt; equivalence~%")))
 (termination 
  (lambda (term)
    (format t "property -&gt; termination~%"))))

(reachable
 (CANREACH_KW LBRACE identifier-list RBRACE
  (lambda (canreach-kw lbrace ids rbrace)
    (format t "reachable -&gt; CANREACH_KW LBRACE identifier_list RBRACE~%"))))

(acceptance
 (ACCEPTS_KW LBRACE string-list RBRACE
  (lambda (accepts-kw lbrace strings rbrace)
    (format t "acceptance -&gt; ACCEPTS_KW LBRACE string_list RBRACE~%"))))

(determinism
 (DETERMINISTIC_KW
  (lambda (det-kw)
    (format t "determinism -&gt; DETERMINISTIC_KW~%"))))

(emptiness
 (ISEMPTY_KW
  (lambda (empty-kw)
    (format t "emptiness -&gt; ISEMPTY_KW~%"))))

(equivalence
 (EQUAL_KW LBRACE identifier-list RBRACE
  (lambda (equal-kw lbrace ids rbrace)
    (format t "equivalence -&gt; EQUAL_KW LBRACE identifier_list RBRACE~%"))))

(termination
 (TERMINATES_KW LBRACE string-list RBRACE
  (lambda (terminates-kw lbrace strings rbrace)
    (format t "termination -&gt; TERMINATES_KW LBRACE string_list RBRACE~%"))))

(string-list
 (STRING COMMA string-list
  (lambda (str comma str-list)
    (format t "string_list -&gt; STRING COMMA string_list~%")))
 (STRING 
  (lambda (str)
    (format t "string_list -&gt; STRING~%"))))

(identifier-list
 (IDENTIFIER COMMA identifier-list
  (lambda (id comma id-list)
    (format t "identifier_list -&gt; IDENTIFIER COMMA identifier_list~%")))
 (IDENTIFIER 
  (lambda (id)
    (format t "identifier_list -&gt; IDENTIFIER~%"))))

(transition-rule-list
 (transition-rule transition-rule-list
  (lambda (rule rule-list)
    (format t "transition_rule_list -&gt; transition_rule transition_rule_list~%")))

 (transition-rule
  (lambda (rule)
    (format t "transition_rule_list -&gt; transition_rule~%"))))

)
</code></pre>
We can then create a function to take in a noam input file and parse it using the lexer and parser we just created as so :
<pre><code>(defun parse-noam-file (filename)
  "Parse a Noam file and write reductions to reductions.txt"
  (with-open-file (output-stream "reductions.txt" 
                                :direction :output 
                                :if-exists :supersede 
                                :if-does-not-exist :create)
    ;; Temporarily bind *standard-output* to our file stream
    (let ((*standard-output* output-stream))
      (with-open-file (input-stream filename :direction :input)
        (let* ((file-contents (make-string (file-length input-stream)))
               (read-chars (read-sequence file-contents input-stream)))
          (parse-with-lexer 
           (noam-lexer (subseq file-contents 0 read-chars))
           *noam-print-reductions*))))))

</code></pre>
Here is a very simple noam file :
<pre><code>Verify A2 {
terminates {"0011"};
equal {A1};
}
</code></pre>
And we get this in the <code>reductions.txt</code> file :</p>

<p><pre><code>string_list -&gt; STRING
termination -&gt; TERMINATES_KW LBRACE string_list RBRACE
property -&gt; termination
identifier_list -&gt; IDENTIFIER
equivalence -&gt; EQUAL_KW LBRACE identifier_list RBRACE
property -&gt; equivalence
property_list -&gt; property SEMICOLON
property_list -&gt; property SEMICOLON property_list
verification_declaration -&gt; VERIFY_KW IDENTIFIER LBRACE property_list RBRACE
dec -&gt; verification_declaration
declist -&gt; epsilon
declist -&gt; dec declist
program -&gt; declist

</code></pre>
Basically, First the STRING (<code>"0011"</code>) is Identified and reduced to  string_list.</p>

<p>Then the termination keyword (<code>terminates {"0011"};</code>)  is reduced to termination nonterminal.</p>

<p>Then the termination nonterminal is reduced to property.</p>

<p>And So On..</p>

<p>Until we get declist reduced to program, which is our start symbol.</p>

<p>Therefore the input has been parsed successfully.</p>

<p><p align="center" style="line-height:1.5">
<img src="../pics/kimi.png" alt=""  style="width:100%;height:auto;max-width:370px" />
</p></p>
    </div>

<h2 style="line-height:0"> Tags </h2>
<hr>
    
|  
<a href='https://xemadp.github.io/blog/tags/tutorial.html'>tutorial </a> |  
<a href='https://xemadp.github.io/blog/tags/technology.html'>technology </a> |  
<a href='https://xemadp.github.io/blog/tags/learning.html'>learning </a> |  
<a href='https://xemadp.github.io/blog/tags/compilers.html'>compilers </a> |  
<a href='https://xemadp.github.io/blog/tags/commonlisp.html'>commonlisp </a> |  

</body>
</head>
</html>
